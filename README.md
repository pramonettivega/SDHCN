# Fire-Ready-Forests-Data-Challenge



## üìä Data Description

This project uses two primary datasets for training and evaluation:

1. **Field-Collected Treelist Data**  
   Sourced from standardized forest inventory surveys across multiple sites in California, this dataset includes in-situ measurements of individual trees. Key attributes include tree height, diameter, and species annotations. 
   Data files:  
   - `01_plot_identification.csv`  
   - `03_tree.csv`

3. **FastFuels (FF) Treelist Data**  
   Derived from TLS (Terrestrial Laser Scanning) analysis and modeling, this dataset provides estimated structural characteristics (e.g., height and diameter) along with species codes inferred from remote sensing methods. This is generated by algorithms in Sprint 3: TL_w_ALS.ipynb
   Data file:  
   - `FF_treelist_all.csv`

To support classification tasks such as predicting plant functional types (PFT), genus, and species, we also use:

- **Species-to-PFT Mapping**  
  A reference table mapping species codes and names to standardized genus and PFT labels.  
  Data file:  
   - `FIATreeSpeciesCode_pft.csv`

## üå≤ TLS Data Description (Test Data)

The TLS (Terrestrial Laser Scanning) dataset is used as the test set for evaluating model predictions. It contains tree-level structural measurements extracted from high-resolution LiDAR scans, and serves as the target for predicting labels such as Plant Functional Type (PFT), genus, and species. The test dataset is prepared through combining those two datasets.</p>

 Data file:  
   - `TLS_treelist.csv`
   - `blk_plot_identification.csv`


## üöÄ Running the Project

### 1. Install Dependencies

Make sure you have Python 3.8+ and `pip` installed. From the root directory of the project, install all required dependencies using:

```bash
pip install -r requirements.txt
```

### 2. Launch Jupyter Notebook

To run the modeling pipeline and reproduce results:

1. Open the Jupyter environment:
    ```bash
    jupyter notebook
    ```

2. In your browser, open the notebook file:
    ```
    sprint4-SDHCN.ipynb
    ```

3. Run all cells sequentially to process data, train models, and generate results.

> üìÅ Ensure all necessary data files (e.g., `01_plot_identification.csv`, `FF_treelist_all.csv`, etc.) are located in the correct paths as expected by the notebook, typically in a `data/` directory.




## üîó References
<ol>
  <li>
    Anthony Marcozzi et al. ‚Äú<strong>FastFuels: Advancing wildland fire modeling with high-resolution 3D fuel data and data assimilation</strong>.‚Äù 
    <em>Environmental Modelling and Software</em>, vol. 183, 2025, p. 106214. 
    <a href="https://doi.org/10.1016/j.envsoft.2024.106214" target="_blank">https://doi.org/10.1016/j.envsoft.2024.106214</a>.
  </li>
  <li>
    U.S. Department of Agriculture, Forest Service, Northern Research Station. 
    <strong>Forest Inventory and Analysis Database</strong>. Technical report. St. Paul, MN: U.S. Department of Agriculture, Oct. 2024. 
    Available online: 
    <a href="https://apps.fs.usda.gov/fia/datamart/datamart.html" target="_blank">https://apps.fs.usda.gov/fia/datamart/datamart.html</a>.
  </li>
  <li>
    U.S. Geological Survey. 
    <strong>3D Elevation Program Lidar Point Cloud</strong>. Accessed April 13, 2025. 2023. 
    <a href="https://www.usgs.gov/the-national-map-data-delivery" target="_blank">https://www.usgs.gov/the-national-map-data-delivery</a>.
  </li>
</ol>

